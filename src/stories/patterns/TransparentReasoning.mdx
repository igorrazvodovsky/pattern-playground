import { Meta, Story } from '@storybook/addon-docs/blocks';
import { LLMReasoning as LLMReasoningStory } from './ActivityLog.stories';

<Meta title="Patterns/Transparent reasoning" />

# Transparent reasoning

Presents the [bot's](../?path=/docs/patterns-bot--docs) reasoning as a thread of visible, inspectable
messages, each expressing a step, decision, action, or assumption in natural language.

Steps are arranged sequentially, like a conversation or narrative, with separation between user inputs,
model responses, and intermediate reasoning steps. Actors can scroll, expand, comment on,
or revisit earlier steps — and if needed, branch the thread to explore alternatives.

## Representation

### Linear

Linear presentation helps break down complex tasks into a series of simpler, sequential subtasks, making the model’s reasoning process more interpretable and transparent.

<Story of={LLMReasoningStory} />

### Branching

The nature of reasoning in LLMs, and human reasoning more broadly, is more nuanced than a simple linear chain.

TODO:

{/* https://d3js.org/d3-hierarchy */}

## Placement

### In a chat

...

### In a task

...

## Actions

...

{/* ### Correcting the bot */}

## Related patterns

### Concepts

- [Task](../?path=/docs/concepts-task--docs) - Makes the task execution process visible through step-by-step reasoning
- [Event](../?path=/docs/concepts-event--docs) - Each reasoning step is recorded as an Event with AI as Actor
- [Event log](../?path=/docs/concepts-event-log--docs) - Maintains chronological sequence of reasoning Events for audit trail

### Precursors

- [Bot](../?path=/docs/patterns-bot--docs) - generates the reasoning that transparent reasoning makes visible and inspectable.

### Follow-ups

- [Activity log](../?path=/docs/patterns-activity-log--docs) - records the reasoning steps for review and audit.

### Complementary

- [Explanation](../?path=/docs/patterns-explanation--docs) - encourages understanding through interaction, while transparent reasoning shows the step-by-step process.
- [Messaging](../?path=/docs/compositions-messaging--docs) - provides the conversational interface where transparent reasoning can be displayed.
- [Suggestions](../?path=/docs/patterns-suggestion--docs) - can emerge from the visible reasoning process.
- [Collaboration](../?path=/docs/patterns-collaboration--docs) - Transparent reasoning makes AI decision-making processes inspectable for human collaborators
- Transparent reasoning can be seen as "TODO:workflow unpacking": in an LLM-driven system, reasoning processes can be viewed as dynamically generated workflows that emerge during runtime rather than being predefined.

## Resources & references

Rock Yuren Pang, K. J. Kevin Feng, Shangbin Feng, Chu Li, Weijia Shi, Yulia Tsvetkov, Jeffrey Heer, Katharina Reinecke. 2025. [Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models](https://arxiv.org/pdf/2506.23678)
