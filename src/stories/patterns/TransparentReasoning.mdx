import { Meta, Story } from '@storybook/addon-docs/blocks';
import { LLMReasoning as LLMReasoningStory } from './ActivityLog.stories';

<Meta title="Patterns/Transparent reasonining*" />

# Transparent reasonining

Presents the [bot's](../?path=/docs/patterns-bot--docs) reasoning as a thread of visible, inspectable
messages, each expressing a step, decision, action, or assumption in natural language.

Steps are arranged sequentially, like a conversation or narrative, with separation between user inputs,
model responses, and intermediate reasoning steps. Actors can scroll, expand, comment on,
or revisit earlier steps â€” and if needed, branch the thread to explore alternatives.

<Story of={LLMReasoningStory} />

## Variants

### In a chat

...

### In a task

...

## Actions

...

{/* ### Correcting the bot */}

## Related patterns

### Precursors

- [Bot](../?path=/docs/patterns-bot--docs) - generates the reasoning that transparent reasoning makes visible and inspectable.

### Follow-ups

- [Activity log](../?path=/docs/patterns-activity-log--docs) - records the reasoning steps for review and audit.

### Complementary

- [Explanation](../?path=/docs/patterns-explanation--docs) - encourages understanding through interaction, while transparent reasoning shows the step-by-step process.
- [Messaging](../?path=/docs/compositions-messaging--docs) - provides the conversational interface where transparent reasoning can be displayed.
- [Suggestions](../?path=/docs/patterns-suggestion--docs) - can emerge from the visible reasoning process.

### Notes

- Transparent reasoning can be seen as "[workflow] unpacking": in an LLM-driven system, reasoning processes can be viewed as dynamically generated workflows that emerge during runtime rather than being predefined.