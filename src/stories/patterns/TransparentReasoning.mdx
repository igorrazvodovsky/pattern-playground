import { Meta, Story } from '@storybook/addon-docs/blocks';
import { LLMReasoning as LLMReasoningStory } from './ActivityLog.stories';

<Meta title="Patterns/Transparent reasoning" />

> ðŸ™‚ **Fun meter: 5/5**. A part of a bigger attempt to map LLM-related patterns.

# Transparent reasoning

Presents the [bot's](../?path=/docs/patterns-bot--docs) reasoning as a thread of visible, inspectable
messages, each expressing a step, decision, action, or assumption in natural language.

Steps are arranged sequentially, like a conversation or narrative, with separation between user inputs,
model responses, and intermediate reasoning steps. Actors can scroll, expand, comment on,
or revisit earlier steps â€” and if needed, branch the thread to explore alternatives.

## Temporal modes

Breaking down reasoning transparency by when it occurs in the execution lifecycle makes the timing distinction explicit.

### Before execution: planning

TODO: Presents complete, verified information before commitment, building trust through transparency of upcoming actions.

### During execution: stream of thought

Reveals reasoning as work unfolds, enabling monitoring and early intervention.

<Story of={LLMReasoningStory} />

### After execution: Retrospective analysis

TODO: Condensed summary after completion, supporting learning and debugging.

## Representation structures

Beyond temporal positioning, reasoning can be structured as linear sequences or branching explorations.

- Linear: presentation breaks down complex tasks into a series of simpler, sequential subtasks, making the model's reasoning process more interpretable and transparent. Most implementations of Stream of Thought and Action Plan use linear structures.
- TODO: Branching: The nature of reasoning in LLMs, and human reasoning more broadly, is more nuanced than a simple linear chain.

{/* https://d3js.org/d3-hierarchy */}

## Placement

### In a chat

...

### In a task

...

## Actions

...

{/* ### Correcting the bot */}

## Related patterns

### Precursors

- [Bot](../?path=/docs/patterns-bot--docs) - generates the reasoning that transparent reasoning makes visible and inspectable.

### Follow-ups

- [Activity log](../?path=/docs/patterns-activity-log--docs) - records the reasoning steps for review and audit.

### Complementary

- [Explanation](../?path=/docs/patterns-explanation--docs) - encourages understanding through interaction, while transparent reasoning shows the step-by-step process.
- [Messaging](../?path=/docs/compositions-messaging--docs) - provides the conversational interface where transparent reasoning can be displayed.
- [Suggestions](../?path=/docs/patterns-suggestion--docs) - can emerge from the visible reasoning process.
- [Collaboration](../?path=/docs/patterns-collaboration--docs) - Transparent reasoning makes AI decision-making processes inspectable for human collaborators
- Transparent reasoning can be seen as "TODO:workflow unpacking": in an LLM-driven system, reasoning processes can be viewed as dynamically generated workflows that emerge during runtime rather than being predefined.
â€“ [Learnability](../?path=/docs/qualities-learnability--docs) â€“ by observing *why* the system made a decision, users implicitly learn the system's logic and capabilities.

## Resources & references

Rock Yuren Pang, K. J. Kevin Feng, Shangbin Feng, Chu Li, Weijia Shi, Yulia Tsvetkov, Jeffrey Heer, Katharina Reinecke. 2025. [Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models](https://arxiv.org/pdf/2506.23678)
