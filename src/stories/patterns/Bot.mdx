import { Meta } from '@storybook/addon-docs/blocks';

<Meta title="Patterns/Bot" />

> ðŸ™‚ **Fun meter: 4/5**. A part of a bigger attempt to map LLM-related patterns.
For now I stick with â€˜botâ€™ over â€˜agentâ€™ or â€˜assistantâ€™ because those tend to carry baggage about capabilities and autonomy.

# Bot

A bot interprets actor intent and returns relevant outputâ€”text, UI, or actions. It acts as an adaptable mediator between actor goals and system functionality, especially when intent is fuzzy or workflows are complex. This umbrella term encompasses all user-facing AI interactionsâ€”from chatbots to agentic systems and beyond.

## Agency

Bot patterns embody different levels of system agency from the agency [spectrum](../?path=/docs/foundations-agency--docs#spectrum):

1. Chatbot: User-driven interaction requiring explicit prompts
2. Inline: Assistance mode providing contextual help and smart suggestions
3. Workflow automation: autonomous action that follows predefined sequence
4. Full autonomy: proactive monitoring and acting without direct user input

Higher agency modes require more careful preservation of [user agency](../?path=/docs/foundations-agency--docs) to maintain control and transparency.

## Modes of interaction

- Focused: Bot as a primary interface, typically via [messaging](../?path=/docs/compositions-messaging--docs).
- Inline: Contextual interactions embedded directly in the UI, such as autocompletions, rewrite suggestions, or smart defaults.
- Ambient: Behind-the-scenes monitoring or support, offering proactive help or taking actions without direct prompting.

## Variants

### Single-turn interactions

Simple query-response patterns without state persistence or tool use. Classic chatbots often operate in this mode.

### Multi-turn conversations

Maintaining context across exchanges, allowing for clarification, follow-ups, and evolving understanding.

### Tool-augmented agents

Bots that can invoke external capabilitiesâ€”from simple calculations to complex API calls. This includes the *bounded loop execution* pattern where agents run tools iteratively until reaching objectives.

{/* ### Autonomous workflows */}
{/* Self-directed execution following predefined or learned patterns, with varying degrees of human oversight. */}

## Memory

### Short-term

Conversation context provides implicit short-term memory, allowing bots to maintain state across interactions within a session.

### Long-term

Persistent memory requires explicit implementation through:
- Storage tools (databases, files, vector stores)
- Retrieval mechanisms with semantic search
- Memory management strategies to prevent unbounded growth

{/* ## Functional flexibility */}

{/* Bots adapt their behaviour across a spectrum of capabilities: */}

{/* ### Response generation */}

{/* - Template-based: Structured responses from predefined patterns */}
{/* - Retrieval-augmented: Combining learned knowledge with external information */}
{/* - Generative: Creating novel responses from learned distributions */}
{/* - Hybrid approaches: Mixing deterministic and probabilistic elements */}

{/* ### Task orchestration */}

{/* - Linear execution: Step-by-step progression through defined workflows */}
{/* - Branching logic: Conditional paths based on context and outputs */}
{/* - Recursive decomposition: Breaking complex tasks into manageable subtasks */}
{/* - Emergent planning: Dynamic strategy formation based on intermediate results */}

{/* ### Confidence mapping */}

{/* Integrated with *input-output mapping*, it's aimed to increase transparency by indicating the bot/model's confidence in different parts of its response. */}

{/* ## Limitations and anti-patterns */}

{/* ### Fundamental limitations */}
{/* - No genuine accountability: Bots cannot take responsibility for actions or form independent intentions */}
{/* - Bounded understanding: Operating within learned or programmed patterns without true comprehension */}
{/* - Context degradation: Performance deteriorates with extended interactions or complex state */}
{/* - Hallucination risks: Potential for generating plausible but incorrect information */}

{/* ### Anti-patterns to avoid */}
{/* - Human replacement fallacy: Assuming bots can fully replace human judgement and accountability */}
{/* - Over-automation: Applying bots to tasks requiring genuine human understanding or empathy */}
{/* - Undefined boundaries: Unclear capabilities leading to user frustration or misuse */}
{/* - Memory sprawl: Implementing persistence without proper management strategies */}
{/* - Complexity creep: Adding features without considering overall system coherence */}
{/* - Trust without verification: Assuming bot outputs are always accurate or appropriate */}

## Related patterns

### Precursors
{/* Primarily establish clear expectations, prepare mental models, and facilitate effective input to enhance subsequent bot interactions. */}

<div>
- [Agency](../?path=/docs/foundations-agency--docs) - how much freedom the bot has to act on its own.
- [Onboarding](../?path=/docs/patterns-onboarding--docs), priming, and [suggestions](../?path=/docs/patterns-suggestion--docs) are the first steps that help people get to know the botâ€”what it can and can't do, and how to get the most out of it.
- [Progressive disclosure](../?path=/docs/patterns-progressive-disclosure--docs) â€“ bots often operate well with incremental complexity. Progressive disclosure keeps things simple at first and helps actors build confidence.
</div>

### Follow-ups

- Bot can use [messaging](../?path=/docs/compositions-messaging--docs) to [converse](../?path=/docs/patterns-conversation--docs) with actors.
- [Prompt](../?path=/docs/patterns-prompt--docs) describes ways of providing input to the bot.
- LLM [settings](../?path=/docs/patterns-intelligence-llm-settings--docs) help keep users in control while the bot does its thing.
- [Generated content](../?path=/docs/patterns-generated-content--docs) - presentation and manipulation of AI's output.
- [Transparent reasoning](../?path=/docs/patterns-transparent-reasoning--docs) makes bot's decision-making process visible and inspectable.
- [Activity log](../?path=/docs/patterns-activity-log--docs) tracks bot actions and reasoning for transparency and review.
- [Collaboration](../?path=/docs/patterns-collaboration--docs) - Bots participate as collaborative agents with adaptable mediation capabilities

### Concepts

- [Task](../?path=/docs/concepts-task--docs) - Bots interpret task specifications and execute work using available tools and capabilities

{/* Input assistance - predictive text, autocomplete, and smart suggestions that aid actor input. */}
{/* TODO: alt. for inline and ambient modes */}


## Resources & references
- Nardi, B., Miller, J. R., & Wright, D. J. (1998). [Collaborative, programmable intelligent agents](https://dl.acm.org/doi/10.1145/272287.272331). Communications of the ACM, 41(3), 96â€“104.
- [Personalization features for Human-LLM Interactions](https://www.arxiv.org/pdf/2503.00681) by Thu, Kocaballi Â· 2025
- [Agents](https://simonwillison.net/2025/Sep/18/agents/) by Simon Willison Â· 2025
- [Why chatbots are not the future](https://wattenberger.com/thoughts/boo-chatbots) by Amelia Wattenberger Â· 2024
- [Expanding conversational user interfaces](https://www.lukew.com/ff/entry.asp?2018) by Luke Wroblewski Â· 2023