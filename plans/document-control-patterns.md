# Document Control Patterns from Agency Review

**Status**: Planning
**Priority**: High
**Related**: [2507.06000v1-notes.md](../resources/papers/2507.06000v1-notes.md), [Agency.mdx](../src/stories/foundations/Agency.mdx), [Collaboration.mdx](../src/stories/patterns/Collaboration.mdx)

---

## Overview

Document the 12 control mechanisms identified in the Human-AI Co-creation Agency Review as design patterns with descriptions and related papers.

**Source**: Zhang, Wang, Yi (2025) - Section 6: Control Mechanisms

---

## Input: Information Access

### [ ] 1. Guided Input Interaction

**Description needed**:
- User-centered input optimization
- Interface-supported input guidance
- Multimodal input integration

**Related papers** (from notes):
- [5, 6, 8, 9, 11, 14, 16, 23, 27, 30, 31, 37, 40, 45, 49, 51, 55, 59, 60, 64, 70, 84, 85, 89, 90, 98, 101, 102, 105, 108, 109, 111-113, 115, 122, 124, 129, 130, 135, 138, 148, 153, 162-164, 166, 171, 172, 177, 178, 181, 182, 187, 189, 191, 199, 201, 207]

**Key examples to extract**:
- [102] Lin et al. - Text-to-image prompt engineering
- [70] Hoque et al. - Interface-supported guidance
- [189] Design principles for generative AI

**Page references**: §6.1, Mechanism-1, p.13

---

### [ ] 2. Context Awareness and Memory Retention

**Description needed**:
- Interaction history integration
- Environmental and spatial awareness
- Task-oriented context management
- Personalized context adaptation

**Related papers**:
- [8, 9, 11, 14, 16, 21, 31, 37, 44, 49, 51, 55, 59, 60, 64, 73, 82, 85, 90, 98, 101, 108, 109, 129, 130, 135, 138, 148, 162-164, 171, 172, 178, 184, 187, 189, 199, 201, 206, 207]

**Key examples to extract**:
- [51] Fan et al. - ContextCam (environmental data integration)
- [55] Fu et al. - Interaction history in AIMC tools
- [148] Sharma et al. - Conversational history

**Page references**: §6.1, Mechanism-2, p.14

---

### [ ] 3. Transparency and Explainability

**Description needed**:
- Interaction tracking
- Decision visualization
- System explanation
- Ideological reflection

**Related papers**:
- [5, 6, 8, 9, 11, 16, 18, 23, 27, 30, 31, 37, 40, 44, 49, 55, 59, 60, 62, 64, 70, 73, 74, 82, 85, 90, 98, 101, 105, 108, 109, 111-113, 122, 124, 125, 129, 130, 135, 138, 148, 153, 162-164, 166, 171, 172, 175, 177, 178, 181, 182, 184, 187, 189, 199, 201, 206, 207]

**Key examples to extract**:
- [70] Hoque et al. - HALLMARK (provenance tracking)
- [18] Berge et al. - Decision visualization for nurses
- [207] Zhou et al. - Visualizing algorithmic processes
- [187] Wang et al. - Surfacing incident reports

**Page references**: §6.1, Mechanism-3, p.14

---

## Action: Exploration

### [ ] 4. Multimodal Action Space Exploration

**Description needed**:
- Text-based interaction
- Visual interaction
- Multi-sensory and physical interaction
- Combined and integrated modalities

**Related papers**:
- [6, 8, 11, 14, 16, 18, 21, 23, 27, 37, 44, 51, 55, 60, 73, 85, 90, 108, 111, 113, 129, 130, 135, 153, 163, 164, 171, 177, 178, 181, 182, 187, 189, 199, 206, 207]

**Key examples to extract**:
- [51] ContextCam - Integrating text, voice, photos, sensor data
- [84] Sound generation with visual feedback
- [178] Combining sketches and gestures
- [11] Visual, auditory and kinesthetic elements

**Page references**: §6.2, Mechanism-4, p.14-15

---

### [ ] 5. Action Coordination

**Description needed**:
- Complementary role distribution
- Human-dominated agency with AI support
- Shared creative agency
- Technical precision and control
- Autonomous AI contribution with human frameworks

**Related papers**:
- [5, 8, 11, 14, 21, 23, 27, 31, 40, 44, 45, 51, 55, 59, 60, 62, 64, 70, 73, 74, 89, 90, 98, 101, 105, 108, 109, 115, 122, 125, 130, 135, 138, 153, 162, 163, 172, 175, 177, 178, 184, 187, 189, 199, 201, 206, 207]

**Key examples to extract**:
- [8] Anthraper et al. - Complementary roles in mentoring
- [70] Hoque et al. - Human-AI role distribution in writing
- [207] Zhou et al. - Shared creative agency in prosthetics
- [189] Weisz et al. - Design principles for role allocation

**Page references**: §6.2, Mechanism-5, p.15

---

### [ ] 6. Attention-focused Processing

**Description needed**:
- Directing system focus to critical data elements
- Allocating processing resources to key aspects
- Attention mechanisms in complex tasks

**Related papers**:
- [70, 84, 115, 189]

**Key examples to extract**:
- [70] Hoque et al. - Interface design focusing writer attention
- [186] PromptCharm - Cross-attention techniques
- Attention distribution visualization

**Page references**: §6.2, Mechanism-6, p.15

---

## Output: Direct Intervention

### [ ] 7. Modification and Intervention

**Description needed**:
- Direct editing and adjustment
- Parameter and prompt control
- Real-time intervention and adjustment
- Acceptance or rejection of AI suggestions

**Related papers**:
- [6, 9, 16, 18, 27, 30, 37, 40, 44, 45, 59, 64, 70, 74, 82, 90, 109, 111-113, 124, 135, 138, 148, 153, 162, 164, 175, 177, 184, 187, 189, 191, 199, 207]

**Key examples to extract**:
- [70] Manually labeling/modifying generated text
- [191] Identifying and correcting AI-generated code errors
- [207] Manipulating visual design elements through gestures
- [18] Users overriding system suggestions

**Page references**: §6.3, Mechanism-7, p.15

---

### [ ] 8. Adaptive Scaffolding

**Description needed**:
- System-controlled adaptive scaffolding
- User-driven adaptive scaffolding
- Hybrid adaptive scaffolding
- Adaptation factors (proficiency, task phase, feedback, progress)

**Related papers**:
- [8, 9, 11, 14, 18, 23, 30, 31, 45, 55, 60, 64, 74, 98, 101, 105, 108, 109, 112, 125, 129, 130, 135, 138, 162, 163, 172, 175, 177, 178, 181, 182, 189, 199, 201]

**Key examples to extract**:
- [18] Berge et al. - AI suggesting relevant questions based on flow
- [45] Dhillon et al. - Varying scaffolding levels (sentence vs paragraph)
- [60] Gmeiner et al. - Adapting assistance to designer skill
- [98] Tailoring support based on learner understanding

**Page references**: §6.3, Mechanism-8, p.15-16

---

### [ ] 9. Chain-of-Thought

**Description needed**:
- Explicitly displaying AI's step-by-step reasoning
- Making thought process visible
- Improving transparency and user understanding
- Enhancing evaluation of outputs

**Related papers**:
- [51, 107, 122, 189, 201, 206]

**Key examples to extract**:
- [107] Liu et al. - CoT prompting for research questions
- [206] Zheng et al. - CoT documentation for AI suggestions
- [189] Providing rationales for outputs
- [51] Few-shot CoT for problem-solving

**Page references**: §6.3, Mechanism-9, p.16

---

## Feedback: Stressing

### [ ] 10. Confidence Visualization

**Description needed**:
- Confidence/uncertainty visualization
- User feedback and trust management
- Confidence-based ranking and prioritization
- User self-efficacy enhancement

**Related papers**:
- [8, 59, 82, 112, 148, 189, 206]

**Key examples to extract**:
- [189] Visualizing confidence scores/intervals
- [148] Feedback channels for trust management
- [59] Pattern prioritization based on confidence
- [8] PeerConnect - Boosting user confidence

**Page references**: §6.4, Mechanism-10, p.16

---

### [ ] 11. Explanatory Feedback Emphasis

**Description needed**:
- Model explanation and reasoning disclosure
- Visual highlighting and differentiation
- User control and interactive transparency
- Contrast and metaphorical representation

**Related papers**:
- [11, 16, 23, 44, 49, 59, 62, 70, 73, 102, 108, 109, 115, 129, 165, 172, 189]

**Key examples to extract**:
- [102, 171] Interpreting ambiguous outputs
- [11] Feature importance plots
- [70] Color-coding AI-written text
- [165] Highlighting key points in peer reviews
- [40] Contrasting old/new tech to critique opacity

**Page references**: §6.4, Mechanism-11, p.16-17

---

### [ ] 12. Iterative Feedback Loop

**Description needed**:
- User-directed feedback
- System-initiated feedback
- Bidirectional interaction feedback
- Continuous refinement cycles

**Related papers**:
- [5, 6, 8, 9, 11, 14, 16, 18, 21, 23, 27, 30, 31, 37, 40, 44, 49, 51, 59, 60, 62, 64, 70, 73, 74, 82, 84, 85, 90, 98, 101, 102, 105, 108, 109, 111-113, 115, 122, 124, 125, 129, 130, 135, 138, 148, 153, 162-164, 171, 172, 175, 177, 178, 181, 182, 187, 189, 199, 201, 206, 207]

**Key examples to extract**:
- [102] Using AI outputs to inform subsequent prompts
- [70] Direct interaction feedback/ratings
- [107] Textual feedback on generated content
- [207] Adjusting movements based on real-time visualizations
- [11] Iterative refinement in workshops
- [40] User-system response cycles

**Page references**: §6.4, Mechanism-12, p.17

---

## Documentation Structure

For each pattern, create:

1. **Pattern name** (from mechanism)
2. **Intent** (what problem it solves)
3. **Description** (how it works)
4. **Anatomy** (key components)
5. **Variants** (different approaches from papers)
6. **States** (interaction states)
7. **Related patterns** (connections to other mechanisms)
8. **Implementation examples** (from key papers)
9. **Accessibility considerations**
10. **Decision tree** (when to use)

---

## Tasks

### Research Phase
- [ ] Read full descriptions for each mechanism in paper (§6.1-6.4, p.13-17)
- [ ] Extract key examples from cited papers
- [ ] Map mechanisms to existing patterns in design system
- [ ] Identify overlaps and relationships between mechanisms

### Writing Phase
- [ ] Document patterns 1-3 (Input mechanisms)
- [ ] Document patterns 4-6 (Action mechanisms)
- [ ] Document patterns 7-9 (Output mechanisms)
- [ ] Document patterns 10-12 (Feedback mechanisms)

### Integration Phase
- [ ] Add cross-references to [Agency.mdx](../src/stories/foundations/Agency.mdx)
- [ ] Update [Collaboration.mdx](../src/stories/patterns/Collaboration.mdx) with mechanism details
- [ ] Create Sankey-style flow diagram showing mechanism relationships
- [ ] Add to pattern library navigation

### Validation Phase
- [ ] Review against paper's framework (Figure 1)
- [ ] Check all paper citations are accurate
- [ ] Verify alignment with existing design system patterns
- [ ] Test pattern application to example scenarios

---

## Notes

- Paper uses IPOF model (Input-Process-Output-Feedback) from Wiener [192]
- Most prevalent mechanism: **Iterative Feedback Loop** (~70+ papers)
- Second most common: **Transparency & Explainability** (~60+ papers)
- These patterns are **evidence-based** from systematic review of 134 papers
- Focus on **operational detail** - how agency is actually implemented in practice

---

## Open Questions

- Should these be documented as separate patterns or as aspects of Agency/Collaboration?
- How to handle overlaps (e.g., transparency appears in multiple mechanisms)?
- Do we need visual examples/diagrams for each pattern?
- Should we create interactive demos showing these patterns in action?

---

**Created**: 2025-09-30
**Target completion**: TBD
