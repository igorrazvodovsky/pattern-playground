# AI, Help Me Think—but for Myself - Notes

## Metadata
- **Title**: AI, Help Me Think—but for Myself: Assisting People in Complex Decision-Making by Providing Different Kinds of Cognitive Support
- **Authors**: Zhang et al. (Inferred from text context)
- **Year**: 2024 (Inferred)
- **Source/Conference**: arXiv:2504.06771v1
- **Link**: https://arxiv.org/html/2504.06771v1
- **Tags**: #research, #ai, #decision-making, #agency, #cognitive-support

## 1. Executive Summary
The paper explores two distinct paradigms for AI assistance in complex decision-making (specifically financial investment):
1.  **RecommendAI**: Provides specific solutions (recommendations) which users evaluate.
2.  **ExtendAI**: Asks users for their rationale and provides feedback/extensions to that rationale without giving specific solutions.

**Key Finding**: While users were split on preference (some wanted the efficiency of recommendations, others the agency of thinking for themselves), **ExtendAI led to better decision outcomes** (more diversified portfolios) and **better understanding** of risks. RecommendAI led to over-reliance and a disconnect between confidence and actual outcome quality. The paper highlights a tension between "Actionability" (ease of use) and "Cognitive Engagement" (deep thinking).

## 2. Key Concepts & Frameworks
- **Cognitive Extension (ExtendAI)**: A mechanism where the AI acts as a critic or sparring partner, extending the user's thought process rather than replacing it.
- **Recommendation (RecommendAI)**: The traditional "recommender system" approach.
- **Tensions in AI Assistance**:
    - **Actionability vs. Cognitive Engagement**: Specific recommendations are actionable but reduce engagement. Feedback is engaging but less immediately actionable.
    - **New Insights vs. Consistency**: Users want new ideas but also validation of their own thinking.
    - **Timing**: Early assistance (RecommendAI) vs. Late assistance (ExtendAI - after user formulates rationale).
- **Over-reliance**: Users trusting recommendations without understanding, leading to "blame shifting" when things go wrong.

## 3. Design Implications (General)
- **Force Rationale Articulation**: Requiring users to write down *why* they are doing something allows the AI to provide much higher quality, context-aware feedback.
- **Withhold Solutions**: In complex domains where "learning" or "ownership" is important, explicitly *not* giving the answer can be a feature, not a bug.
- **Subtle Influence**: "ExtendAI" was effective but subtle; users didn't always realize how much it helped. Design needs to make this value visible.

## 4. Technical Architecture / Implementation Details
- **Prototype**: Financial investment simulator (ETF trading).
- **AI Model**: GPT-4o.
- **Inputs for ExtendAI**: User's current portfolio + User's written rationale + Market data.
- **Prompting**: "Improve the user's rationale by drawing on knowledge of return, volatility, and diversification... highlight blind spots."

## 5. Application to Pattern Playground

### 5.1 Existing Foundations Analysis
*   **`src/stories/foundations/Agency.mdx`**:
    *   **Assessment**: **Partial**. We discuss agency, but this paper provides a concrete trade-off ("Actionability vs Cognitive Engagement") that we should explicitly document. The concept of "Cognitive Extension" is a specific *mode* of agency.
*   **`src/stories/patterns/Suggestion.mdx`**:
    *   **Assessment**: **Aligned**. This maps to "RecommendAI". We should add warnings about over-reliance and the "blame shifting" phenomenon observed in the paper.
*   **`src/stories/concepts/conversational/Intervention.mdx`**:
    *   **Assessment**: **Related**. ExtendAI is a form of "Intervention" where the system intervenes in the *thought process*.
*   **`src/stories/patterns/TransparentReasoning.mdx`**:
    *   **Assessment**: **Related**. This is about the AI explaining *its* reasoning. ExtendAI is about the AI critiquing the *user's* reasoning.

### 5.2 Gap Analysis
*   **Missing Pattern: "Critique" or "Refinement"**: We lack a pattern that explicitly describes the "ExtendAI" interaction model: User inputs draft/rationale -> AI critiques/extends -> User refines. This is distinct from "Suggestion" or "Correction".
*   **Missing Concept: "Rationale Articulation"**: We don't have a standardized way to ask the user "Why?". This is a powerful input for AI context.

### 5.3 Proposed Features / Refactors

#### Proposal A: New Pattern `Critique.mdx` (or `Refinement.mdx`)
*   **Goal**: Document the "ExtendAI" pattern.
*   **Changes**:
    *   Create `src/stories/patterns/Critique.mdx`.
    *   Define the flow: Input -> Rationale -> Critique -> Refinement.
    *   Contrast with `Suggestion`.

#### Proposal B: Update `Agency.mdx`
*   **Goal**: Incorporate the "Actionability vs Cognitive Engagement" trade-off.
*   **Changes**:
    *   Add a section on "Cognitive Support Strategies".
    *   Define "Extension" vs "Offloading" (Recommendation).

#### Proposal C: Update `Suggestion.mdx`
*   **Goal**: Add "Risks" section based on RecommendAI findings.
*   **Changes**:
    *   Add warning about over-reliance and "blame shifting".

### 5.3 Action Items
- [ ] Create `src/stories/patterns/Critique.mdx`
- [ ] Update `src/stories/foundations/Agency.mdx`
- [ ] Update `src/stories/patterns/Suggestion.mdx`
